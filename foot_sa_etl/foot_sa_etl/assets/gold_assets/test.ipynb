{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Optional\n",
    "from great_tables import GT\n",
    "from pattern.en import sentiment\n",
    "\n",
    "\n",
    "# Third-party library imports\n",
    "from bs4 import BeautifulSoup\n",
    "from dotenv import load_dotenv\n",
    "import polars as pl\n",
    "\n",
    "# Dagster imports\n",
    "from dagster import (\n",
    "    AssetExecutionContext,\n",
    "    MaterializeResult,\n",
    "    asset\n",
    ")\n",
    "\n",
    "# Add project root to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.abspath(''), '../..')))\n",
    "\n",
    "# Local project utility imports\n",
    "from utils.azure_blob_utils import (\n",
    "    create_blob_client_with_connection_string, \n",
    "    read_all_parquets_from_container, \n",
    "    write_blob_to_container, \n",
    "    read_blob_from_container, \n",
    "    merge_dataframes_on_id\n",
    ")\n",
    "from utils.common_helpers import generate_hash\n",
    "\n",
    "# load assets bronze_scrappe_epl_news\n",
    "# in order to be used as dependency\n",
    "from assets.bronze_assets.scrappe_epl_news import bronze_scrappe_epl_news\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# Get path of the config file\n",
    "scrapper_config_path = os.path.join(sys.path[-1], 'scrapper_config.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON file\n",
    "with open(scrapper_config_path, 'r') as file:\n",
    "    scrapper_config = json.load(file)\n",
    "\n",
    "# Load environment variables\n",
    "connection_string = os.environ.get(\"CONN_STRING_AZURE_STORAGE\")\n",
    "if connection_string is None:\n",
    "    raise EnvironmentError(\"Azure storage connection string not found in environment variables.\")\n",
    "\n",
    "# Create a blob client for Azure Blob Storage\n",
    "blob_service_client = create_blob_client_with_connection_string(connection_string)\n",
    "# List all blobs in the container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read parquet file from silver/epl_news/processed_data.parquet\n"
     ]
    }
   ],
   "source": [
    "silver_container_name = scrapper_config['silver_container_name']\n",
    "folder_name = scrapper_config['folder_name']\n",
    "\n",
    "df = read_all_parquets_from_container(silver_container_name, folder_name, blob_service_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table 'dim_article' -> ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dim_article_table(df):\n",
    "    team_df = get_team_table(df)\n",
    "\n",
    "    df_processed = df \\\n",
    "        .rename({\"id\": \"article_id\"}) \\\n",
    "        .rename({\"title\": \"article_title\"}) \\\n",
    "        .rename({\"publishedDate\": \"published_at\"}) \\\n",
    "        .rename({\"teamName\": \"team_name\"}) \\\n",
    "        .join(team_df, on=\"team_name\") \\\n",
    "        .rename({\"team_id\": \"fk_team_id\"}) \\\n",
    "        .select([\"article_id\", \"fk_team_id\", \"article_title\", \"published_at\"])\n",
    "    \n",
    "    return df_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create 'Reaction' table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_pro_reactions(df):\n",
    "    # Define regex patterns to match unwanted strings in the 'title' column\n",
    "    patterns_to_filter = [\n",
    "        r\"Did you know?\",\n",
    "        r\"the fans' verdict\",\n",
    "        r\"Gossip\"\n",
    "    ]\n",
    "\n",
    "    # Combine the patterns into a single regex expression with the OR operator (|)\n",
    "    combined_pattern = \"|\".join(patterns_to_filter)\n",
    "\n",
    "    # Filter out rows where the 'title' column contains any of the unwanted patterns\n",
    "    df_filtered = df.filter(~pl.col(\"title\").str.contains(combined_pattern))\n",
    "\n",
    "    return df_filtered\n",
    "\n",
    "def get_fact_pro_reaction_table(df):\n",
    "    df_processed = keep_pro_reactions(df)\n",
    "\n",
    "    df_processed = df_processed \\\n",
    "        .rename({\"id\": \"fk_article_id\"}) \\\n",
    "        .rename({\"publishedDate\": \"published_at\"})\n",
    "\n",
    "    df_processed = df_processed.with_columns(\n",
    "        reaction_id = pl.col(\"fk_article_id\") + '_pro'\n",
    "    )\n",
    "\n",
    "    df_processed = df_processed.with_columns(\n",
    "        is_fan = False\n",
    "    )\n",
    "\n",
    "    return df_processed.select([\"reaction_id\", \"fk_article_id\", \"content\", \"published_at\", \"is_fan\"])\n",
    "\n",
    "# Define a function to extract fan reactions\n",
    "def extract_reactions(content, publishedDate, article_id):\n",
    "    reactions = []\n",
    "\n",
    "    # Start extracting after \"Here are some of your comments:\"\n",
    "    content_after_comments = content.split(\"Here are some of your comments:\")[-1].strip()\n",
    "\n",
    "    # Regex pattern to extract fan reactions (assuming \"Fan Name: Reaction\" format)\n",
    "    pattern = re.compile(r'(\\w+):\\s+(.+?)(?=\\w+:|$)', re.DOTALL)\n",
    "    matches = pattern.findall(content_after_comments)\n",
    "    \n",
    "    for idx, (fan_name, reaction) in enumerate(matches, start=1):\n",
    "        reactionId = f\"{article_id}_fan_{idx}\"  # Create unique reactionId using articleId and index\n",
    "        reactions.append((reactionId, reaction.strip(), publishedDate, article_id))\n",
    "    \n",
    "    return reactions\n",
    "\n",
    "def get_fact_fan_reaction_table(df):\n",
    "    # Define regex patterns to match unwanted strings in the 'title' column\n",
    "    patterns_to_filter = r\"the fans' verdict\"\n",
    "\n",
    "    # Filter rows where the 'title' column contain a particular pattern\n",
    "    df_filtered = df.filter(pl.col(\"title\").str.contains(patterns_to_filter))\n",
    "\n",
    "    # Apply the extraction function to the dataframe\n",
    "    reaction_list = []\n",
    "    for row in df_filtered.iter_rows(named=True):\n",
    "        reaction_list.extend(extract_reactions(row['content'], row['publishedDate'], row['id']))\n",
    "\n",
    "    # Create a new dataframe for the extracted reactions\n",
    "    df_processed = pl.DataFrame(reaction_list, schema=['reaction_id', 'content', 'published_at', 'fk_article_id'], orient=\"row\")\n",
    "\n",
    "    df_processed = df_processed.with_columns(\n",
    "        is_fan = True\n",
    "    )\n",
    "\n",
    "    return df_processed.select(['reaction_id', 'fk_article_id', 'content', 'published_at', 'is_fan'])\n",
    "\n",
    "def create_reaction_table(df):\n",
    "    df_fan = get_fact_fan_reaction_table(df)\n",
    "    df_pro = get_fact_pro_reaction_table(df)\n",
    "    return pl.concat([df_fan, df_pro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
