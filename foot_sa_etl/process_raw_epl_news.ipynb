{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.bbc.com/sport/football/teams/arsenal?page=1'\n",
    "response = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Find all articles based on the class\n",
    "articles = soup.find_all('span', class_='ssrcss-189b1h2-HeadlineWrap')\n",
    "\n",
    "for article in articles:\n",
    "    # Extract title\n",
    "    title = article.find('span').get_text()\n",
    "    \n",
    "    # Extract published date\n",
    "    timestamp = article.find('span', {'data-testid': 'timestamp'})\n",
    "    if timestamp:\n",
    "        published_date = timestamp.find('span', {'data-testid': 'accessible-timestamp'}).get_text()\n",
    "    else:\n",
    "        published_date = \"No date found\"\n",
    "    \n",
    "    # Extract all paragraphs related to the article\n",
    "    text_content = []\n",
    "    paragraphs = article.find_parent('article').find_all('p', class_='ssrcss-1q0x1qg-Paragraph e1jhz7w10')\n",
    "    for p in paragraphs:\n",
    "        text_content.append(p.get_text())\n",
    "\n",
    "    full_text = ' '.join(text_content)\n",
    "\n",
    "    # Print or store results\n",
    "    print(f\"Title: {title}\")\n",
    "    print(f\"Published Date: {published_date}\")\n",
    "    print(f\"Text: {full_text}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
